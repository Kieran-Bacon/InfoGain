This thesis defines a multi–label classification problem for extracting the relation candidates
from a question. We target a widely used question dataset [15], which is crawled from
WikiAnswer and consists of a set of questions with over 19K relations. We assume that
these open–domain questions have only first–order relations, which we call single–relation
questions, for example, “Who’s the president of the United States? ” has a first–order
relation, but “Who’s the wife of the United States’ president? ” has a second–order relation.
Single–relation questions are the most commonly observed ones in QA sites [16]. However,
since human expressions or understanding could be ambiguous, each question may have
several relation candidates, for example, “What is the primary duty of judicial branch? ”
has relation candidates “be–primary–responsibility–of ”, “be–primary–role–of ”, and “have–
role–of ”. Thus we address the problem as recognizing the relations inside a question in a
multi–label manner.
1.3
Contributions
We explore various deep learning models to solve the proposed multi–label recognition prob-
lem. At the first step, we exploit the widely used word2vec [33] [35] [36] to represent each
word as a 300 dimensional vector, and the whole sentence as a matrix by stacking all the
word vectors. Word2vec converts the semantic relations between words into the distance
of their vectors, for example, word2vec(‘Paris’) - word2vec(‘France’) + word2vec(‘China’)
= word2vec(‘Beijing’).
Based on the matrix representation of each sentence, we propose two kinds of convolu-
tional neural networks (CNNs): Parallel CNN and Deep CNN. Convolutional layers of both
networks can learn phrases, such as “where do . . . live”, and “the population of”. Parallel
CNN is a shallow network but has multiple parallel convolutional layers. Deep CNN, on
the contrary, has multiple serial convolutional layers. Our experiments show that both
Parallel and Deep CNN outperform the traditional Support Vector Classification (SVC)–
based method by a large margin. Furthermore, we observe that Deep CNN has better
performance than Parallel CNN, indicating that the deep structure enables much stronger
semantic learning capacity than the wide but shallow network.
21.4
Thesis Organization
Section 2 mainly background knowledge of the structures and components of CNNs. Sec-
tion 3 introduces recent research on CNNs for NLP tasks. Section 4 presents the dataset,
tools, and environment used in this work. Section 5 describes our method and shows
experimental results. Section 6 concludes this thesis.
3Chapter 2
Background
2.1
Deep Neural Network
Deep learning has shown powerful feature learning skills and achieved remarkable perfor-
mance in computer vision (CV) [8] [43], speech recognition [11] [21], and natural language
processing (NLP) [9]. Deep neural network is a kind of deep learning method. The dif-
ference between deep neural network (DNN) and shallow artificial neural network (ANN)
is that the former contains multiple hidden layers so that it can learn more complex fea-
tures. It has several variants: convolutional neural network, recurrent neural network, and
recursive neural network. DNNs have forward pass and back propagation. The parameters
of networks are updated according to learning rate, cost function via stochastic gradient
descent during the back propagation. In the following, we briefly introduce the structures
of di↵erent DNNs applied in NLP tasks.
2.1.1
Convolutional Neural Network
Convolutional neural networks (CNNs) learn local features and assume that these features
are not restricted by their absolute positions. In the field of NLP, they are applied in
Part–Of–Speech Tagging (POS), Named Entity Recognition (NER) [9], etc.
0
1
x 0
Figure 2.1 shows a two–layer CNN. For the green node h 0 = f (W @ x 1 A + b) =
x 2
4Figure 2.1: Convolutional Neural Network. Neurons in CNN are locally connected with
neurons in previous layer. Weights of the same filter are shared across the same layer.
0
1
x 1
f (w 0 x 0 + w 1 x 1 + w 2 x 2 + b) and for the green node h 1 = f (W @ x 2 A + b) = f (w 1 x 1 +
x 3
w 2 x 2 + w 3 x 3 + b). W is shared by the same filter in the same layer.
2.1.2
Recurrent Neural Network
The limitation of convolutional neural network is that they take fixed–sized inputs and pro-
duce fixed–sized outputs. Recurrent neural networks (RNNs) can operate over sequential
input and predict sequential output. They can do one–to–one, one–to–many, many–to–
one, many–to–many jobs. They can be used in machine translation [34] and other NLP
tasks.
Figure 2.2 shows a simple recurrent neural network with three layers: input layer x, hid-
den layer h and output layer y. Horizontal arrows stand for time changing. Input sequence:
x 1 , x 2 , . . . , x T . For each time step t, h t = f (W hh h t 1 + W hx x t ) and y t = g(W hy h t ), where
W hh , W hx and W hy are parameters shared across time sequence. Hidden layer’s states are
influenced by all the previous inputs. It also has a bidirectional structure to incorporate
both forward and backward inputs. RNN has a vanishing or exploding gradient problem,
as shown in Figure 2.3, while initializing weight matrix to identity matrix [46] and using
ReLU activation function [29] address this problem to a certain degree.
5Figure 2.2: Recurrent Neural Network. RNN takes input sequence. Weights of hidden
units are updated according to current input and previous weights of hidden units at each
time step. Outputs of RNN are calculated according to current hidden units state.
Figure 2.3: Error Surface of a Single Hidden Unit RNN [41].
62.1.3
Recursive Neural Network
Recursive neural networks (RNNs) have been applied to multiple NLP tasks, such as
sentence classification [47].
Figure 2.4: Recursive Neural Network.
Figure 2.4 shows a simple recursive neural network. Each node takes two children as
inputs. h = f (W x + b) ✓ and ◆ y = U T h. For example, for the green node, the parent of
x 0
x 0 and x 1 , h 01 = f (W
+ b), and for the purple node, the parent of h 01 and x 2 ,
x 1
✓
◆
h 01
h 012 = f (W
+ b). In CNNs, weights are shared within the same filter, while in
x 2
RNNs, weights are shared across di↵erent layers. Recursive neural networks have di↵erent
composition functions: Matrix–Vector RNNs, Recursive Neural Tensor Networks, Tree
LSTM, etc.
Recursive neural networks require parsers to get the semantic structures of the sen-
tences. Recurrent neural networks are good at dealing with learning time–sequential fea-
tures. Convolutional neural networks have good performances in classification and are used
as models for the task described in this thesis.
72.2
Motivation and History
Convolutional Neural Networks are inspired by a cat’s visual cortex. Visual cortex contains
a complex arrangement of cells. These cells are responsible for detecting small sub–fields
of the visual field, called receptive fields. The sub–fields are tiled to cover the whole visual
field. These cells act as local filters over the input space and are well–suited to exploit the
strong spatially local correlation present in natural images.
Neocognitron was introduced by Fukushima in 1980 [18] and improved in 1998 by
LeCun, Bottou, Bengio, and Ha↵ner [30]. They proposed the famous LeNet–5 — a con-
volutional neural network. Then it was generalized by Behnke [6], and pre-digested by
Simard and his collaborators in 2003 [45]. Convolutional neural networks perform well on
problems such as recognizing handwritten numbers, but the computational power at that
time limited their ability to solve more complex problems until the rise of efficient GPU
computing.
2.3
Basic Assumption
The convolutional layer is based on the assumption that features are learned regardless of
their absolute positions. This is reasonable in many cases, for example in image learning,
if detecting a horizontal edge is important at some location in the image, it should also be
useful at other locations.
Convolutional layers focus on learning local features. In natural language processing,
if in the sentence “give me an example of thank you letter” example of has been learned
as a feature, then it should also be recognized in sentence “what is an example of scientific
hypothesis”. But example of may not have any relation with thank you letter or scientific
hypothesis. For example in audio recognition, features of time spans of audio clips are
learned instead of that of the whole input audio.
2.4
Review of Discrete Convolution Definition
Recall the definition of convolution for a 1D signal [12]. The discrete convolution of f and
g is given by:
o[n] = f [n] ⇤ g[n] =
1
X
f [u]g[n
u= 1
u] =
1
X
u= 1
8
f [n
u]g[u].
(2.1)This can be extended to 2D as follows:
o[m, n] = f [m, n] ⇤ g[m, n] =
2.5
1
1
X
X
f [u, v]g[m
u, n
v]
(2.2)
u= 1 v= 1
Volumes of Neurons
The neurons in convolutional neural networks are arranged in three dimensions: depth,
width, and height.
If the network is for image classification, images are in size of 3 ⇥ 32 ⇥ 32 (three colour
channels, 32 wide, 32 high). The size of input layer is 3 ⇥ 32 ⇥ 32. The size of hidden layer
is 12 ⇥ 16 ⇥ 16 in which 12 is the number of feature maps and 16 is the width and height
of a feature map. The size of output layer is 10 ⇥ 1 ⇥ 1 where 10 is the number of classes
to be learned.
If the network is for sentence classification, a sentence has 34 words and each word is
represented by 300 dimensional vector. The size of input layer is 1 ⇥ 34 ⇥ 300. The size of
hidden layer might be 256 ⇥ 17 ⇥ 1 where 256 is the number of feature maps. The output
layer has 46 ⇥ 1 ⇥ 1 dimensions for 46 class classification.
2.6
Architecture
Three types of layers build up a convolutional neural network: Convolutional Layer, Pooling
Layer, and Fully Connected Layer.
2.6.1
Convolutional Layer
Convolutional layers have attributes shown below:
• Sparse connectivity: makes each neuron focuses on local features.
• Weight shared: increases learning efficiency by reducing the number of free parame-
ters being learnt.
9Figure 2.5: Sparse Connectivity.
In Figure 2.5, in layer i, a neuron is connected with contiguous neurons which are the
subset of the neurons in layer i 1. Connection between two connected neuron represents
convolution of filter (kernel ) and input. Each filter has smaller size along width and height
but has the same depth as the input.
Figure 2.6: Shared Weights. Connections with same colour share weights.
10Each filter learns a feature map. In the forward pass, when applying convolutional
computing, each filter is slid across the width and height and the dot product is computed
between the entries of filter and the corresponding inputs. In Figure 2.6, weights of the
same colour are shared. In the back propagation process, calculating the gradient of a
shared weight is to sum up the gradients of the parameters being shared.
A convolutional layer always has a set of filters. Feature maps learned by di↵erent
filters are stacked along depth dimension.
Figure 2.7: Convolutional Layer [26].
11In Figure 2.7, input has size of d i ⇥ w i ⇥ h i = 3 ⇥ 5 ⇥ 5. Input is padded with 0s of
width w p = 1 and height h p = 1. The depth of output (or the number of feature maps to
be learned) d o is 2. The size of filter is d o ⇥ d f ⇥ w f ⇥ h f = 2 ⇥ 3 ⇥ 3 ⇥ 3. The strides
when filter is slid along width w s and height h s are both 1. The feature map h k , which is
learned by the filter k, is determined by the weights W k and bias b k as follows:
h k = f (W k ⇤ x + b k )
(2.3)
, where f is an activation function which will be introduced in Subsection 2.6.5. The
volume of output should be:
d o ⇥ (
w i
w f + 2w p
h i
+ 1) ⇥ (
w s
h f + 2h p
+ 1)
h s
(2.4)
The number of parameters to be learned should be:
(w f · h f · d f + 1) · o d
(2.5)
i.e., The output has size of 2 ⇥ 3 ⇥ 3. The number of parameters to be learned is (3 ⇥ 3 ⇥
3 + 1) ⇥ 2 = 56.
In regular neural networks, every neuron is fully connected with all neurons in the
previous layer. If the sizes of input and output are the same, the number of parameters of
a fully connected neural network becomes (w i ·h i ·d i +1)·w o ·h o ·d o = (7⇥7⇥3+1)⇥3⇥3⇥2 =
2664. The number of parameters in a convolutional neural network is positively correlated
with the size of the filter, while that in a regular neural network is positively correlated
with the size of the input and the output. But the size of filter is much smaller than that
of input and output. The number of parameters in regular neural network is very large
as every layer is fully connected with neighbour layers, which sometimes makes learning
process overfitting.
2.6.2
Pooling Layer
To describe a large matrix, one natural approach to down sample is to aggregate statistics.
Common methods include computing the mean value, max value and L2–norm of particular
size. By doing this, the problem of overfitting is addressed to a certain degree.
Figure 2.8 shows an example of a 24 ⇥ 9 matrix doing 3 ⇥ 3 max pooling with stride
three. The depth is one in this example. Pooling only applies to width and height.
12Figure 2.8: Pooling Layer.
The width, height and depth of input are w i , h i and d i . The pooling size is d p ⇥ w p ⇥ h p .
Usually let d p = d i . The stride of pooling has the size of w s ⇥ h s . It is not common to use
zero–padding for Pooling layers. The output should have size:
d i ⇥ (
w i
w p
w s
+ 1) ⇥ (
h i
h p
h s
+ 1)
(2.6)
In most cases, input is pooled non–overlapping, i.e., w s = w p and h s = h p . So the output
has size:
w i
h i
d i ⇥
⇥
(2.7)
w p h p
, which reduces the size of output by
1
.
w p ·h p
In the forward pass, indexes are recorded during pooling in order to do back propaga-
tion.
2.6.3
Fully Connected Layer
Convolutional neural networks always have several fully connected layers following convo-
lutional layers. Neurons in fully connected layers have full connections with all neurons in
13the previous layer. The structure of a fully connected layer is same as that of layer in a
regular neural network.
2.6.4
Dropout
Figure 2.9: Dropout.
Dropout is a technique to prevent neural networks from overfitting and approximate a
way to combine exponentially di↵erent neural network architectures [49]. When training
the model, the unit to be dropped out has a probability p to be temporarily removed from
the network, as shown in Figure 2.9. It will be ignored when calculating input and output
both in the forward pass and the back propagation progress. Temporarily means this unit is
only dropped out when training this specific sample. This prevents units from co–adapting
too much. A layer with n units can be seen as 2 n possible thinned neural networks. When
testing the model, all units will not be dropped out and their weights will be multiplied
by p. By doing this, 2 n networks with the same parameters are combined into one neural
network.
Usually, dropout is applied only to fully connected layers (except the last layer), not to
convolutional layers or pooling layers.
14Figure 2.10: Activation Function Applied to a Neuron.
2.6.5
Activation Function and Cost Function
Without activation functions, a layer neural network can only define linear hypotheses.
Before calculating the output of a neuron, the value is applied a activation function, as
shown in Figure 2.10.
Several activation functions can be applied in neural networks.
• Sigmoid Function
1
1 + exp( z)
0
f (z) = f (z)(1 f (z))
f (z) =
(2.8)
(2.9)
f : < 7! [0, 1]
• Hyperbolic Tangent (tanh)
f (z) = tanh(z) =
f 0 (z) = 1
f : < 7! [ 1, 1]
15
e z e
e z + e
f (z) 2
z
z
(2.10)
(2.11)Figure 2.11: Activation Functions. This figure shows sigmoid, tanh and ReLU function.
As seen from the figure, sigmoid’s output range is [0, 1], while tanh’s output range is [ 1, 1]
and ReLU’s output range is [0, +1]
• Rectifier (ReLU)
f (z) = max(0, z)
f 0 (z) =
(
(2.12)
0, z < 0
1, z > 0
(2.13)
f : < 7! [0, +1]
Loss function is also called cost function. For multi–label task, binary cross entropy is
the most common used loss function.
• Binary Cross Entropy
z(t, o) =
(tlog(o) + (1
16
t)log(1
o))
(2.14)2.6.6
Common CNN Architectures
Most common convolutional neural networks follow the pattern below [26]:
Input
! [(Convolutional ! Activation) ⇤ ! P ooling?] ⇤
! (F C ! Dropout? ! Activation) ⇤
! Output
(2.15)
, where “*” indicates that this layer might be repeated multiple times and “?” stands for
optional occurring. Input layer is followed by multiple convolutional and pooling layers,
then is followed by several fully connected layers with dropout.
17Chapter 3
Related Work
Convolutional neural networks have been widely used in POS tagging [43], chunking, NER,
semantic role labeling [10], searching queries and Web documents [44], sentence classifica-
tion [13] [27], semantic modelling [25], relation classification [14], and other NLP tasks.
3.1
Single–Convolutional–Layer CNNs
Figure 3.1: Neural Network for Relation Classification and Framework for Extracting Sen-
tence Level Features [55]. In the right hand figure, WF stands for word features and PF
stands for position features.
18Zeng et al. [55] exploit a neural network to classify questions. Lexical level features
are extracted from word embeddings. Sentence level features are learned by a one layer
convolutional neural network. Then both lexical and sentence level features are fed into a
neural network to predict the relationship of two given nouns in a sentence, as shown in
Figure 3.1. This model is experimented on the SemEval–2010 Task 8 dataset (a question
set with 10 labels [20]).
Figure 3.2: CNN Model [44].
Figure 3.3: CNN Model [51].
Shen et al. [44] and Yih et al. [51] present similar convolutional neural networks. They
both transform word into vector using letter–tri–gram. Then word vectors are fed into a
convolutional layer, followed by a max over–time pooling layer and a fully connected layer
as output layer. Figure 3.2 shows the model for queries and web documents searching [44].
Shen et al. [51] test the model on a question set from a commercial search engine. Yih et
al. use a question dataset, which is the same dataset as in this thesis, and train a model for
relation extraction and another model for entity extraction, as shown in Figure 3.3. The
authors define this problem as a multi–class classification, i.e., given a query returning one
relation each time while returning 150 top–scoring candidates.
Kim [27] trains a network with one convolutional layer followed by a max–over time
pooling, and a fully connected layer with dropout and softmax output layer for sentence
classification, as shown in Figure 3.4. This “one convolutional layer” consists of 3 parallel
convolutional layers with di↵erent filter sizes. The model is trained with two channels –
only the parameters of one channel are updated in training progress. word2vec is input
feature. This model is experimented on: movie reviews with positive/negative labels [40]
(MR), Stanford Sentiment Treebank, (SST–1, which is dataset with movie reviews with
19Figure 3.4: CNN Model for Several Sentence Classification Tasks [27].
very positive, positive, neutral, negative, very negative label [48]), same dataset as SST–1
but only positive/negative labels, sentences with subjective/objective labels [39] (Subj),
Text REtrieval Conference question dataset with 6 labels [32] (TREC), customer reviews
with positive/negative labels [23] (CR), opinion dataset with positive/negative labels [52]
(MPQA).
3.2
Multi–Convolutional–Layer CNNs
Figure 3.5: ARC–II Model [22].
Hu et al. [22] propose a convolutional neural network model for matching sentences. The
authors apply a 1 dimension convolution followed by 1 dimension max pooling, multiple 2
20dimension convolutions and pooling layers, and multiple fully connected layers, as shown
in Figure 3.5. It takes embedding of words in the sentences aligned as input and outputs
matching degree. The approach is tested on sentence completion [31], matching a response
to Weibo, and MSRP dataset [42]
Figure 3.6: DCNN Model for Modeling Sentence [25].
Kalchbrenner et al. [25] design a Dynamic k–Max Pooling Convolutional Neural Net-
work (DCNN) for sentence modelling. The authors apply several wide one–dimensional
convolution layer followed by feature maps folding operation and k–max pooling layer, and
a fully connected layer as output, which is shown as Figure 3.6. K–max pooling is to chose
k highest values among inputs and keep their original orders. This model is tested on
SST–1, SST–2, 6–type question categorization in the TREC dataset, and Twitter senti-
ment prediction task (tweets with positive/negative labels). Compared with Kim’s model,
21DCNN performs better on SST–1 and TREC, while worse on SST–2.
CNNs with only one convolutional layer have good performance on di↵erent tasks.
Kim’s design [27] consists of parallel convolutional layers which is di↵erent from others’.
Some other authors propose deeper CNNs. This thesis proposes a single–layer CNN and
two multi–layer CNNs and compares their performance on di↵erent datasets.
22Chapter 4
Dataset and Environment
4.1
Dataset
This thesis focuses on classifying single–relation questions. Example questions of this
type include: “What is the birthday of Barack Obama?”, “Where does a giant swallowtail
butterfly live?”. Single–relation questions are the most common type of questions observed
in various community QA sites [16]. In a single–relation question, relation and entity are
two elements to be understood. After the relation and the entity are extracted, the answer
can be generated from knowledge base (KB) such as Freebase [2], DBpedia [1], etc.
4.1.1
Data Format
In this thesis, we download the dataset from knowitall.cs.washington.edu/paralex/ [16].
These questions are crawled from WikiAnswer. Typos and grammar errors are very com-
mon in the dataset. “labeled.txt” contains 608,650 examples. Each example is in the
form of (question, query1, query2, . . .), for instance, “what be the di↵erence btw isolation
transformer and step up and step down transformer ? 2 1 755225 1605804 2 1 775854
2464747 2 1 887236 1605804 2 1 890251 1605804 2 0 1503166 ”. Each query is encoded in
the form 2#ORDER#REL#EN T . #REL represents index of relation constants in the
query which can be looked up in “vocab.txt”, such as 755225 stands for be–function–of.r.
Each question might have several relations. All question–queries list tuples are processed
to generate question–relations list tuples in the form of (question, #REL1, #REL2, . . .).
The example mentioned above becomes “what be the di↵erence btw isolation transformer
and step up and step down transformer ? 755225 775854 887236 890251 1503166 ”.
234.1.2
Answerable Queries Coverage
Figure 4.1: The Curve of Coverage of Queries Answerable and Number of Relation.
Figure 4.1 shows the relation between the coverage of answerable queries and the num-
ber of relations. This curve increases steeply before coverage reaches 80% but grows slowly
later. 21 relations cover more than 20% of the queries. But it requires about 16,000 addi-
tional relations to increase the coverage from 80% to 100%. It makes sense that most of
the problems people concern on WikiAnswer are only a small subset of knowledge.
4.2
4.2.1
Tool and Environment
word2vec
Word2vec is a continuous distributed representation of words [33] [35] [36]. A 300 dimen-
sional vectors trained on part of Google News dataset which contains 3 million words and
phrases are used in this experiment.
244.2.2
NER
NER labels named entities. Stanford NER has three models: a four–class model trained
for CoNLL, a seven–class model trained for MUC and a three–class model trained for
both [17] [19]. Models support both capitalization sensitive and ignored classifiers.
4.2.3
CUDA
In order to run experiments on GPU, CUDA driver and CUDA Toolkit are needed for
Nvidia’s GPU–programming toolchain. CUDA Toolkit is downloaded from developer.nvidia.com,
which contains an nvcc program – a compiler for GPU code.
4.2.4
Python Libraries
• Theano is a Python library that defines, optimizes, and evaluates mathematical ex-
pressions involving multi–dimensional arrays efficiently and has transparent use of
GPU [5] [7] [28].
• Keras is a Theano–based deep learning Python library [3]. Keras is used as library
to build CNNs.
• scikit–learn is a Python library for machine learning [4]. scikit–learn is for building
a support vector classifier.
4.2.5
Spelling Corrector
Spelling Corrector is a tool to correct typos [38]. It is used to correct spelling errors in
dataset with pre–trained 3 million words and phrases (GoogleNews–vectors–negative3000)
as dictionary. As questions of are crawled from WikiAnswer, dataset contains many typos
and grammar error. Spelling corrector is helpful to remove noises in dataset.
